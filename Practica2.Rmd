---
title: "Práctica 2"
author: "Juan Pasaret y David Reyes"

date: "2023-06-01"
output:
  html_document:
    toc: yes
    number_sections: yes
    toc_depth: 2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r message=FALSE, warning=FALSE, echo=FALSE}
library(rminer)
library(pROC)
library(corrplot)
library(RColorBrewer)
require(ggplot2)
if (!require('GGally')) install.packages('GGally')
library(GGally)
library(knitr)
library(kableExtra)
```

# Descripción del dataset

El dataset seleccionado para la práctica se denomina [**Heart Attack Analysis & Prediction Dataset**](https://www.kaggle.com/datasets/rashikrahmanpritom/heart-attack-analysis-prediction-dataset)**.**

Es un conjunto de datos de análisis y predición de ataques cardiados. Está diseñado para la práctica de análisis estadístico, ya que el número de muestras es muy pequeño.

El objetivo de la práctica es predecir las posibilidades de sufrir un ataque al corazón y estudiar qué factores son los más influyentes en esta dolencia.

El conjunto está formado por dos ficheros que contienen las siguientes variables.

-   **Age**: Edad del paciente

-   **Sex** : Sexo del paciente

-   **exang**: angina inducida por el ejercicio (1 = sí; 0 = no)

-   **ca**: número de vasos principales (0-3)

-   **cp** : Tipo de dolor torácico

    -   Valor 1: typical angina (angina típica)

    -   Valor 2: atypical angina (angina atípica)

    -   Valor 3: no-anginal pain (dolor no anginoso)

    -   Valor 4: asymptomatic (asintomático)

-   **trtbps**: presión arterial en reposo (en mm Hg)

-   **chol**: colesterol en mg/dl obtenido a través del sensor BMI

-   **fbs**: (azúcar en sangre en ayunas \> 120 mg/dl) (1 = verdadero; 0 = falso)

-   **rest_ecg** : resultados electrocardiográficos en reposo

    -   Valor 0: normal

    -   Valor 1: tener anomalías en la onda ST-T (inversiones de la onda T y/o elevación o depresión del ST \> 0,05 mV)

    -   Valor 2: mostrar hipertrofia ventricular izquierda probable o definitiva según los criterios de Estes

-   **thalach**: frecuencia cardíaca máxima alcanzada

-   **output**:

    -   0= enfermedad cardíaca diagnosticada

    -   1= enfermedad cardíaca diagnosticada

# Integración y selección de los datos de interés a analizar

Carga del fichero:
```{r}
# carga de datos
heart <- read.csv(file = 'heart.csv')
```

Verificamos la estructura del juego de datos principal. Vemos el número de columnas que tenemos y ejemplos de los contenidos de las filas.

```{r}
structure = str(heart)
```

Vemos que tenemos **14** variables y **303**registros.

A continuación vemos una muestra:

```{r}
head(heart, 10)
```

La descripción de las variables ha sido realizada por la autora en [la documentación de kaggle](#https://www.kaggle.com/datasets/rashikrahmanpritom/heart-attack-analysis-prediction-dataset/discussion/329925)

Vamos a factorizar las variables categóricas. Las variables numéricas no categóricas se transforman en variables numéricas. Se factoriza igualmente la variable output, que se utilizará para evaluar la precisión de nuestro modelo:

```{r}
heart.original<-heart
heart$sex<-as.factor(heart$sex)
levels(heart$age)<-c("Mujer","Hombre")

heart$exng<-as.factor(heart$exng)
levels(heart$exng)<-c("No","Yes")

heart$cp<-as.factor(heart$cp)
levels(heart$cp)<-c("Tipical angina","Atypical angina","Non-anginal pain","Asymptomatic")

heart$fbs<-as.factor(heart$fbs)
levels(heart$fbs)<-c("False","True")

heart$restecg<-as.factor(heart$restecg)
levels(heart$restecg)<-c("Normal","ST-T wave abnormality","Left ventricular hypertrophy")

heart$slp<-as.factor(heart$slp)
levels(heart$slp)<-c("unsloping","flat","downsloping")

heart$thall<-as.factor(heart$thall)
levels(heart$thall)<-c("null","fixed defect","normal","reversable defect")

heart$trtbps<-as.numeric(heart$trtbps)
heart$chol<-as.numeric(heart$chol)
heart$thalachh<-as.numeric(heart$thalachh)

#Output es la variable que vamos a utilizar para comparar si nuestro
heart$output<-as.factor(heart$output)
levels(heart$output)<-c("no disease","disease")

```

Comprobamos los transformaciones realizadas:

```{r echo=FALSE}
tabla<-data.frame(variable = names(heart),
           Original = sapply(heart.original, class),
           Final = sapply(heart, class),
           row.names = NULL)
names(tabla)<-c("Variable","Clase original","Clase modificada")
kable(tabla,format="html") %>% kable_styling(bootstrap_options = "striped")
```

# Limpieza de datos

## Valores vacíos

Se comprueba que no hay ninguna columna vacía

```{r}
print(sum(is.na(heart)))
```

## Duplicados

Se observa que hay 1 duplicado, que se decide quitar del dataset.

```{r}
sum(duplicated(heart))
heart<-heart[!duplicated(heart),]
```

## Identificación y gestión de valores extremos

Se identifican valores extremos en las siguientes variables numéricas:\
- **trtbps** : filas 9, 102, 111, 204, 224, 242, 249, 261, 267\
- **chol** : filas 29, 86, 97, 221, 247\
- **oldpeak** : filas 102, 205, 222, 251, 292

```{r,echo=FALSE}
#Creo que este gráfico no tiene sentido en este apartado

#ggpairs(heart,               # Data frame
#        columns = numericas, # Columnas
#        aes(color = output,  # Color por grupo (var. categórica)
#            alpha = 0.5))    # Transparencia
```

```{r,echo=FALSE}
heart.old<-heart
numericas<-c("age","trtbps","chol","thalachh","oldpeak")

rows2Delete<-c()

for (columnName in numericas) {
  q1<-quantile(heart[[columnName]],0.25)
  q3<-quantile(heart[[columnName]],0.75)
  iqr<-q3-q1

  lower<-q1-iqr*1.5
  higher<-q3+iqr*1.5  
  
  outliers_lower<-which(heart[[columnName]]<lower)
  outliers_higher<-which(heart[[columnName]]>higher)
  if (length(outliers_higher) | length(outliers_higher)){
    rows2Delete<-append(rows2Delete,outliers_lower)
    rows2Delete<-append(rows2Delete,outliers_higher)
  }
}

heart<-heart[-rows2Delete,]

```

Se decide quitar las observaciones extremas del dataset. Ejemplo con la variable **trtbps**:

```{r,echo=FALSE}
par(mfrow=c(1,2))
boxplot(heart.old$trtbps,main="Con outliers")
boxplot(heart$trtbps,main="Sin outliers")
```

# Análisis de los datos

## Análisis exploratorio

Este análisis empieza por la exploración del conjunto de observaciones en base al diagnóstico obtenido de cada paciente. Se observa un total de 126 pacientes sin enfermedad cardíaca contra 158 pacientes diagnosticados con enfermedad cardíaca:

```{r, echo=FALSE}
ggplot(heart, aes(x=output)) +
  geom_bar() +  
  labs(x='Result') + 
  scale_x_discrete(labels=c("No heart disease","Heart disease")) +
  ggtitle("Diagnóstico de enfermedad cardíaca")
```

Sin embargo, si se analizan este parámetro en función del sexo, se observa una desproporción en la proporción de mujeres diagnosticadas con dolencia cardíaca frente a los hombres:

```{r, echo=FALSE}
table(heart$output,heart$sex)
```

```{r, echo=FALSE}
ggplot(heart, aes(x=output,fill=sex)) +
  geom_bar() +  
  labs(x='Result') + 
  scale_x_discrete(labels=c("No heart disease","Heart disease")) +
  ggtitle("Diagnóstico de enfermedad cardíaca por sexo")
```

El análisis de componentes principales nos indica que la edad explica el 35% de la varianza en el diagnóstico:

```{r, echo=FALSE}
componentesPrin <- prcomp(heart[,numericas], center = TRUE, scale = TRUE)
summary(componentesPrin)
```

Por lo tanto, se realiza un gráfico del diagnóstico en función de la edad:

```{r,echo=FALSE}
ggplot(heart, aes(x=age,fill=output)) +
+     geom_histogram() +  
+     labs(x='Edad') + 
+     ggtitle("Diagnóstico de enfermedad cardíaca por edad")
```


## Contrastes de hipótesis

dddd

# Normalización de datos

------------------------------------------------------------------------

## Revisión de datos normalizados

Para revisar si las variables pueden ser candidatas a la normalización miramos las graficas de quantile-quantile plot y el histograma.

```{r ,eval=TRUE,echo=TRUE}
par(mfrow=c(2,2))
for(i in 1:ncol(heart)) {
  if (is.numeric(heart[,i])){
    qqnorm(heart[,i],main = paste("Normal Q-Q Plot for ",colnames(heart)[i]))
    qqline(heart[,i],col="red")
    hist(heart[,i], 
      main=paste("Histogram for ", colnames(heart)[i]), 
      xlab=colnames(heart)[i], freq = FALSE)
  }
}
```

Los resultados del quantile-quantile plot nos indica que las variables pueden ser candidatas a la normalización si es necesario.

Para revisar si las variables estan normalizadas se aplica el test de Shapiro Wilk en cada variables numérica.

```{r ,eval=TRUE,echo=TRUE}
shapiro.test(heart$age)
```

```{r ,eval=TRUE,echo=TRUE}
shapiro.test(heart$trtbps)
```

```{r ,eval=TRUE,echo=TRUE}
shapiro.test(heart$chol)
```

```{r ,eval=TRUE,echo=TRUE}
shapiro.test(heart$thalachh)
```

```{r ,eval=TRUE,echo=TRUE}
shapiro.test(heart$oldpeak)
```

```{r ,eval=TRUE,echo=TRUE}
shapiro.test(heart$caa)
```

El test nos indica que sólo la variable **chol** esta normalizada, ya que para el resto de variables el p-valor es inferior al coeficiente 0.05, por lo que se puede rechazar la hipotesis nula y entender que no es normal.

Que no sea normal no quiere decir que no pueda ser normalizable, ya que segun el teorema del limite central al tener mas de 30 elementos en las observaciones podemos aproximarla como una distribución normal de media 0 y desviación estandard 1

# Construcción de un modelo predictivo

## Creción de conjunto training y test

Se decide utilizar separar el conjunto original en un 80% para training y un 20% para test.

```{r}
set.seed(9)
h<-holdout(heart$output,ratio=0.8)
heartTraining<-heart[h$tr,]
heartTest<-heart[h$ts,]
```

## Identificación de correlación

```{r, echo=FALSE}
cor.mtest <- function(mat, ...) {
    mat <- as.matrix(mat)
    n <- ncol(mat)
    p.mat<- matrix(NA, n, n)
    diag(p.mat) <- 0
    for (i in 1:(n - 1)) {
        for (j in (i + 1):n) {
            tmp <- cor.test(mat[, i], mat[, j], ...)
            p.mat[i, j] <- p.mat[j, i] <- tmp$p.value
        }
    }
  colnames(p.mat) <- rownames(p.mat) <- colnames(mat)
  p.mat
}
# matrix of the p-value of the correlation
p.mat <- cor.mtest(heart.original)
```

Se observa que las variables **chol, trtbps y fbs** no están significativamente relacionadas con output.

```{r, echo=FALSE}
M<-cor(heart.original)
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
corrplot(M, method="color", col=col(200),  
         type="upper", order="hclust", 
         addCoef.col = "black", # Add coefficient of correlation
         tl.col="black", tl.srt=45, #Text label color and rotation
         # Combine with significance
         p.mat = p.mat, sig.level = 0.01, insig = "blank", 
         # hide correlation coefficient on the principal diagonal
         diag=FALSE 
         )
```

```{r}
Modelo=glm(formula=output~sex+age+cp+thalachh+exng+oldpeak+slp+caa+thall,
           data=heartTraining,
           family=binomial)

summary(Modelo)
```

## Evaluación del modelo

```{r}
output_predicted <- predict(Modelo,newdata=heartTest,type='response')

#Se asume que la predicción del modelo es 1 si el modelo de regresión logística es 0.8 o mayor.
output_predicted <- ifelse(output_predicted > 0.8,1,0)

matrix_confusion<-table(output_predicted,heartTest$output)
matrix_confusion
```

## Evaluación de la potencia

```{r}
test_roc = roc(heartTest$output~output_predicted, plot = TRUE, print.auc = TRUE)

auc(test_roc)
```

# Resolución del problema, conclusiones
